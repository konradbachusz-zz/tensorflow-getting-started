{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepMNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOYKEPCDTpszWmarbNR9wV+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/konradbachusz/tensorflow-getting-started/blob/master/Keras%20DeepMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGWek7y2Vqy8",
        "colab_type": "code",
        "outputId": "0c82fe6d-7cfa-41a2-e712-471458d0e95f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "!pip uninstall tensorflow\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-1.5.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/freeze_graph\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.6/dist-packages/external/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow-1.5.0.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-1.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53q3rni3WEty",
        "colab_type": "code",
        "outputId": "707e2782-6b4a-474b-97d7-a9aea781036c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "!pip install tensorflow==1.5"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.5\n",
            "  Using cached https://files.pythonhosted.org/packages/04/79/a37d0b373757b4d283c674a64127bd8864d69f881c639b1ee5953e2d9301/tensorflow-1.5.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.5) (0.34.2)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.5) (1.18.2)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.5) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.5) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.5) (3.10.0)\n",
            "Requirement already satisfied: tensorflow-tensorboard<1.6.0,>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.5) (1.5.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow==1.5) (46.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5) (3.2.1)\n",
            "Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5) (1.5.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5) (1.0.0)\n",
            "Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5) (0.9999999)\n",
            "Installing collected packages: tensorflow\n",
            "Successfully installed tensorflow-1.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgZd6zdhzxwW",
        "colab_type": "code",
        "outputId": "458973a2-cf49-4413-84e8-ec9ca05b2e33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"%tensorflow_version 1.5\" "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'%tensorflow_version 1.5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5v6P-iJEhH3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "64e0a0e7-95c9-44f0-e743-3bedea3503b9"
      },
      "source": [
        "#\n",
        "#   DeepMNIST.py - Multiple layer MNIST classifier in tensorflow\n",
        "#\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "# Create input object which reads data from MNIST datasets.  Perform one-hot encoding to define the digit\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "\n",
        "# Using Interactive session makes it the default sessions so we do not need to pass sess\n",
        "sess = tf.InteractiveSession()\n",
        "\n",
        "image_rows = 28\n",
        "image_cols = 28\n",
        "\n",
        "# reshape the training and test images to 28 X 28 X 1 \n",
        "train_images = mnist.train.images.reshape(mnist.train.images.shape[0],image_rows, image_cols, 1)\n",
        "test_images =  mnist.test.images.reshape(mnist.test.images.shape[0], image_rows, image_cols, 1)\n",
        "\n",
        "# Layer values\n",
        "num_filters = 32                # Number of conv filters\n",
        "max_pool_size = (2, 2)          # shape of MaxPool\n",
        "conv_kernel_size = (3, 3)       # conv kernel shape\n",
        "imag_shape = (28,28,1)\n",
        "num_classes = 10\n",
        "drop_prob = 0.5                 # fraction to drop (0-1.0)\n",
        "\n",
        "# Define the model type\n",
        "model = Sequential()\n",
        "\n",
        "# Define layers in the NN\n",
        "# Define the 1st convlution layer.  We use border_mode= and input_shape only on first layer\n",
        "# border_mode=value restricts convolution to only where the input and the filter fully overlap (ie. not partial overlap)\n",
        "model.add(Convolution2D(num_filters, conv_kernel_size[0], conv_kernel_size[1], border_mode='valid',\n",
        "                        input_shape=imag_shape))\n",
        "# push through RELU activation\n",
        "model.add(Activation('relu'))\n",
        "# take results and run through max_pool\n",
        "model.add(MaxPooling2D(pool_size=max_pool_size))\n",
        "\n",
        "# 2nd Convolution layer\n",
        "model.add(Convolution2D(num_filters, conv_kernel_size[0], conv_kernel_size[1]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=max_pool_size))\n",
        "\n",
        "# Fully Connected Layer\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128))   # Fully connected layer in Keras\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# dropout some neurons to reduce overfitting\n",
        "model.add(Dropout(drop_prob))\n",
        "\n",
        "# Readout layer\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Set loss and measurement, optimizer, and metric used to evaluate loss\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',   # was adadelta\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "#   Training settings\n",
        "batch_size = 128\n",
        "num_epoch = 2\n",
        "\n",
        "# fit the training data to the model.  Nicely displays the time, loss, and validation accuracy on the test data\n",
        "model.fit(train_images, mnist.train.labels, batch_size=batch_size, nb_epoch=num_epoch,\n",
        "          verbose=1, validation_data=(test_images, mnist.test.labels))\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1..., padding=\"valid\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:73: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "55000/55000 [==============================] - 65s 1ms/step - loss: 0.3609 - acc: 0.8872 - val_loss: 0.0764 - val_acc: 0.9776\n",
            "Epoch 2/2\n",
            "55000/55000 [==============================] - 65s 1ms/step - loss: 0.1135 - acc: 0.9666 - val_loss: 0.0491 - val_acc: 0.9843\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb420ae2b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    }
  ]
}